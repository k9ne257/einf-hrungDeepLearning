{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aufgabe 1",
   "id": "e4b84e6111537b37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Vorteile von Convolutional Layers gegenüber Fully Connected Layers:\n",
    "\n",
    "Convolutional Layers verwenden Filter, die Parameter teilen, was die Gesamtzahl der zu lernenden Parameter reduziert. Fully Connected Layers benötigen für jeden Knoten im Netzwerk was bei großen Eingaben zu einem exponentiellen Anstieg der Parameter führt.\n",
    "Convolutional Layers erkennen Merkmale unabhängig von ihrer genauen Position im Eingabebild und können durch den Fokus auf lokale Regionen im Bild können Convolutional Layers spezifische Details extrahieren.\n",
    "\n",
    "Sie berücksichtigen die Nachbarschaftsinformationen in Daten (z. B. Bilder), was bei Fully Connected Layers verloren geht.\n",
    "\n",
    "Sie sind weniger speicherintensiv und schneller zu trainieren im Vergleich zu Fully Connected Layers bei denselben Eingaben.\n",
    "    \n",
    "\n",
    "### Nachteile von Convolutional Layers gegenüber Fully Connected Layers:\n",
    "\n",
    "Convolutional Layers sind primär für datenräumliche Beziehungen wie Bilder und Zeitreihen nützlich, während Fully Connected Layers universeller einsetzbar sind.\n",
    "\n",
    "Komplexere Modellierung globaler Beziehungen da Convolutional Layers nur lokale Muster betrachten, benötigen sie oft mehrere Schichten, um globale Muster im gesamten Bild zu lernen.\n",
    "\n",
    "Spezialisierung durch Architektur, weil sie sind stark auf die Gestaltung der Filter und die Architekturparameter (z. B. Filtergröße, Stride) angewiesen, die für unterschiedliche Aufgaben spezifisch sind.\n"
   ],
   "id": "e216b8d982b64336"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aufgabe 2",
   "id": "6c43f7edbf7cc309"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Aufgabe 2a\n",
    "\n",
    "https://www.kaggle.com/code/georgiisirotenko/pytorch-flowers-translearing-ensemble-test-99-67\n",
    "\n",
    "Im Datenvorbereitungsschritt werden die Bilder durch verschiedene Techniken augmentiert und normalisiert, um die Trainingsdaten künstlich zu erweitern und die Robustheit des Modells zu verbessern. Konkret wird Folgendes durchgeführt:\n",
    "\n",
    "    Größenänderung  transform.Resize(): Bilder werden auf eine einheitliche Größe von 220×220220×220 Pixel skaliert.\n",
    "    Farbanpassungen  transform.ColorJitter(): ColorJitter verändert Helligkeit, Kontrast und Sättigung der Bilder.\n",
    "    Rotationen (transform.RandomRotation()) und Transformationen (transform.RandomAffine()): RandomRotation und RandomAffine führen zufällige Rotationen und affine Transformationen wie Skalierung und Verschiebung durch.\n",
    "    Horizontal Flip: Zufälliges horizontales Spiegeln der Bilder.\n",
    "    Random Erasing: Kleine Bildbereiche werden zufällig gelöscht, um Okklusionen zu simulieren.\n",
    "    Normalisierung transform.Normalize(): Die Pixelwerte werden kanalweise normalisiert (Mittelwert und Standardabweichung für jeden Kanal werden angepasst)."
   ],
   "id": "59b3ca1c6568de34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aufgabe 2b",
   "id": "7cd49b41dbc3b450"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Augmentierung hilft, die begrenzte Anzahl an Originalbildern zu erweitern, indem leicht veränderte Versionen der Originalbilder erstellt werden. Durch verbesserung der Generalisierungsfähigkeit lernt das Modell robuster gegenüber Variationen wie Beleuchtung, Perspektive oder anderen äußeren Einflüssen zu sein, die in realen Szenarien auftreten können. Die größere Vielfalt der Daten hilft, um Overfitting zu vermeiden. Transformationen wie Random Erasing oder horizontal Flip simulieren Szenarien wie teilweise verdeckte Objekte oder umgedrehte Perspektiven.",
   "id": "a8d25d2003d81a7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aufgabe 2c",
   "id": "a52d13a36745335c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Die Modelle, DenseNet121, GoogLeNet, ResNet101 & VGG19 sind vortrainiert auf großen Datensätzen (z. B. ImageNet). Dieses vortraining stellt sicher, dass sie bereits allgemeine Merkmale wie Kanten und Texturen erkennen können.\n",
    "\n",
    "Die Modelle werden kombiniert, um die Klassifikation durchzuführen. Das Ensemble-Modell summiert die Ausgaben der einzelnen Modelle und trifft auf Basis der kombinierten Ergebnisse die endgültige Entscheidung. Jedes Modell gibt Wahrscheinlichkeiten für die Klassenzugehörigkeit aus, die dann addiert werden, um die Gesamtwahrscheinlichkeit für jede Klasse zu bestimmen.\n",
    "\n",
    "zu Beginn wird nur der Klassifikator (z. B. das letzte vollständig verbundene Layer) trainiert, während die restlichen Schichten eingefroren bleiben. Nach einigen Epochen werden alle Schichten \"freigeschaltet\" (Unfreezing), sodass das gesamte Netzwerk an die spezifischen Daten angepasst wird.\n",
    "\n",
    "Die Bilder werden den Modellen als Eingabe gegeben. Die Ausgaben der Modelle werden summiert, um die wahrscheinlichste Klasse zu bestimmen. Die Bilder werden in Batches verarbeitet, um Speicher effizient zu nutzen. Parameter wie pin_memory und num_workers optimieren den Datenfluss zwischen CPU und GPU.\n",
    "\n",
    "Das Ensemble liefert die endgültige Vorhersage basierend auf den kombinierten Wahrscheinlichkeiten der Klassen."
   ],
   "id": "ef22392160b30c94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aufgabe 2d",
   "id": "9c807c5549f1311b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Im Fine-Tuning werden in der ersten Phase nur die Gewichte der Klassifikationsschicht trainiert, da alle anderen Schichten des vortrainierten Modells eingefroren sind. Die Klassifikationsschicht wird neu initialisiert, um die spezifischen Klassen des Blumen-Datensatzes zu lernen.\n",
    "\n",
    "In der zweiten Phase, nach dem \"Unfreezing\", werden alle Schichten des Netzwerks trainiert. Dadurch können die vortrainierten Gewichte an die besonderen Merkmale des Blumen-Datensatzes angepasst werden, wie spezifische Farben oder Texturen. Ein Adam-Optimierer aktualisiert die Gewichte basierend auf den Gradienten des Fehlers, und ein Scheduler passt die Lernrate dynamisch an, um die Leistung zu optimieren."
   ],
   "id": "c42f0fc8aebae908"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aufgabe 2e",
   "id": "8bc7cadea20b0a81"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Vollständige wissenschaftliche Quelle:\n",
    "\n",
    "He, K., Zhang, X., Ren, S., & Sun, J. (2015). Deep Residual Learning for Image Recognition. arXiv preprint arXiv:1512.03385.\n",
    "\n",
    "** hier habe ich chatgpt und google scholar verwendet "
   ],
   "id": "27f97a239f0cd5e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aufgabe 2f",
   "id": "eff22e8e55a941cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Indem mehrere Modelle kombiniert werden, kann das Ensemble die individuellen Stärken der einzelnen Modelle nutzen und Schwächen einzelner Modelle ausgleichen, um Vorhersagegenauigkeit zu erhöhen und die Robustheit des Modells zu verbessern.\n",
    "\n",
    "Der Hauptvorteil des Ensembling liegt darin, dass es die Wahrscheinlichkeit von Fehlklassifikationen reduziert und die Generalisierungsfähigkeit auf unbekannte Daten erhöht."
   ],
   "id": "3cb41a9096af0197"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aufgabe 3\n",
   "id": "11d431d8e110a774"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8bfad99b108fe259"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
